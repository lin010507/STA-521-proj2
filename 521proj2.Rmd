---
title: "task1"
author: "Yanjiao Yang, Huiying Lin"
date: "2022-11-15"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(patchwork)
library(GGally)
library(MASS)
library(class)
library(randomForest)
library(caret)
library(gbm)
library(e1071)
library(pROC)
knitr::opts_chunk$set(echo = TRUE)
```

# 1

## b

```{r load data}
imagem1 = read.table("imagem1.txt")
imagem2 = read.table("imagem2.txt")
imagem3 = read.table("imagem3.txt")

# change colnames
names = c("y", "x", "label", "NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")
colnames(imagem1) = names
colnames(imagem2) = names
colnames(imagem3) = names
```

```{r summarize the data}
imagem1 %>%
  group_by(label, .drop=TRUE) %>%
  summarise(n()/dim(.)[1])

imagem2 %>%
  group_by(label, .drop=TRUE) %>%
  summarise(n()/dim(.)[1])

imagem3 %>%
  group_by(label, .drop=TRUE) %>%
  summarise(n()/dim(.)[1])
```

```{r plot maps, cache=TRUE, fig.height=8}
p1 = imagem1 %>%
  filter(label!=0) %>%
  ggplot(aes(x = x, y = y, col = factor(label)))+
  geom_point()+
  scale_color_manual(values = c("grey", "white"))+
  labs(x = "x", y = "y")+
  theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "black"))+
  tune::coord_obs_pred()

p2 = imagem2 %>%
  filter(label!=0) %>%
  ggplot(aes(x = x, y = y, col = factor(label)))+
  geom_point()+
  scale_color_manual(values = c("grey", "white"))+
  labs(x = "x", y = "y")+
  theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "black"))+
  tune::coord_obs_pred()

p3 = imagem3 %>%
  filter(label!=0) %>%
  ggplot(aes(x = x, y = y, col = factor(label)))+
  geom_point()+
  scale_color_manual(values = c("grey", "white"))+
  labs(x = "x", y = "y")+
  theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "black"))+
  tune::coord_obs_pred()

p1+p2+p3+plot_layout(nrow = 1, ncol = 3)


```

## c

```{r pairwise relationship, cache=TRUE}
# library(GGally)
# imagem1 %>%
#   select(V3:V11) %>%
#   ggpairs()
```

```{r corplot, cache=TRUE}
# pairwise correlation between features
imagem1 %>%
  select(NDAI:AN) %>%
  ggcorr(label = TRUE, label_alpha = TRUE, low = "steelblue", mid = "white", high = "darkred")
```

```{r}
imagem2 %>%
  select(NDAI:AN) %>%
  ggcorr(label = TRUE, label_alpha = TRUE, low = "steelblue", mid = "white", high = "darkred")
```

```{r}
imagem3%>%
  select(NDAI:AN) %>%
  ggcorr(label = TRUE, label_alpha = TRUE, low = "steelblue", mid = "white", high = "darkred")
```

```{r relationship between labels and features}
imagem1[,3:11] %>%
  filter(label!=0)  %>%
  group_by(label) %>%
  pivot_longer(cols = "NDAI":"AN", names_to = "feature") %>%
  ggplot(aes(x = label, y = value, group = label))+
  geom_boxplot(outlier.size = 0.1)+
  facet_wrap(~feature, scales = "free")
```

```{r single boxplot}
imagem3[,3:11] %>%
  filter(label!=0)  %>%
  group_by(label) %>%
  pivot_longer(cols = "NDAI":"AN", names_to = "feature") %>%
  ggplot(aes(x = label, y = value, group = label))+
  geom_boxplot(outlier.size = 0.1)+
  facet_wrap(~feature, scales = "free")
```

# 2

## a

### Split image 1 using systematic assignment:

We first use the systematic assignment to split each image. The pattern for the split in image 1 is shown in the figure. The systematic assignment is a valid split as it ensures lower dissimilarity between folds. Among all the 12 blocks of the three images, 2 blocks are selected as the test set. As for the remaining 10 blocks, one block is used for validation and the rest for training when the number of folds $k$ is not greater than 10. If $k$ is larger than 10 (which is not a common case), after each of the 10 blocks has been used for validation, we randomly select one block to construct the additive $k-10$ folds. If $k=12$, for instance, after all the 10 blocks have been in the validation set in turn, we randomly select one block for validation and use the remaining 9 blocks for the training set and repeat this process again such that there are 12 cross validation sets in total. This paper uses 10-fold cross validation to assess the fit of models in the next section. We claim that resampling from the 10 blocks when more than 10 folds are needed generally is reasonable because the number of folds is usually between 5 and 10. [Maybe more justification later]


Referefence: https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.02881

```{r}
systematic.split = function(image, i){
  
  # divide the image into 2T*2T pieces
  T = 4
  image = image %>%
    mutate(level.x = as.factor(cut(image$x, breaks = 2*T)),
           level.y = as.factor(cut(image$y, breaks = 2*T)),)
  levels(image$level.x)=as.character(1:(2*T))
  levels(image$level.y)=as.character(1:(2*T))

  image = image %>%
    mutate(
      mod = (as.integer(level.x) + as.integer(level.y)) %% T) %>%
    mutate(fold = mod+4*i-3) 
  
  return(image %>% dplyr::select(-c(level.x, level.y, mod)))
}
```

```{r}
imagem1.syst = systematic.split(imagem1, i=1)
imagem2.syst = systematic.split(imagem2, i=2)
imagem3.syst = systematic.split(imagem3, i=3)

# combine the three images
image.syst = rbind(imagem1.syst, imagem2.syst, imagem3.syst)

# show the number of data in each fold
table(image.syst$fold)
```

```{r}
# create the test data
image.syst.test = NULL
set.seed(111111)

idx.test = c()
for (i in 1:2){
  idx = sample(1:length(unique(image.syst$fold)), size = 1)
  image.syst.test = rbind(image.syst.test, image.syst[image.syst$fold==idx, ])
  idx.test = c(idx.test, idx)
}

# create training data
image.syst.train = image.syst[!(image.syst$fold %in% idx.test), ]

table(image.syst.test$fold)
table(image.syst.train$fold)
```

```{r}
# plot the split of image1
imagem1.syst %>%
  ggplot(aes(x = x, y = y, col = factor(fold)))+
  geom_point()+
  labs(x = "x", y = "y", color = "Fold")+
  scale_color_brewer(palette = "GnBu")+
  theme_bw()
  #scale_color_grey(start = 0.8, end = 0.2)
ggsave("sys asgmt.png")
```

### Split image 1 using buffering:

The second splitting method separates the training set from the validation set and the test set by creating a buffer. The cross in the middle of the image is used as the test set. For the remaining 12 corners in the three images, one corner is randomly selected for validation and the remaining for training. Although the pixels in the buffer area are not used as either the training set or the test set, the width of the pixels can be modified such that the fraction of the unused data can be controlled. One advantage of this split over the first one is that it generates spatially separated folds and ensures that no validation data or test data abuts the training data.

Reference (buffering): https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13107

```{r}
buf.split = function(image, width, i){
  xcut = quantile(image$x, c(4/9, 5/9, 1))
  ycut = quantile(image$y, c(4/9, 5/9, 1))
  
  image = image %>%
    mutate(
      level.x = case_when(
        ( x > xcut[1] & x < xcut[2]) ~ 0,
        ( x < xcut[1] - width ) ~ 1,
        ( x > xcut[2] + width )  ~ 2,
        TRUE ~ -1),
      level.y = case_when(
        ( y > ycut[1] & y < ycut[2]) ~ 0,
        ( y < ycut[1] - width) ~ 1,
        ( y > ycut[2] + width) ~ 2,
        TRUE ~ -1)
    )
  
  image = image %>%
    mutate(fold = case_when(
      (level.x*level.y == 0) ~ 0,
      (level.x == 1 & level.y == 1) ~ 4*i-3,
      (level.x == 2 & level.y == 1) ~ 4*i-2,
      (level.x == 1 & level.y == 2) ~ 4*i-1,
      (level.x == 2 & level.y == 2) ~ 4*i,
      TRUE ~ -1)
    )
  return (image %>% dplyr::select(-c(level.x, level.y)))
}
```

```{r}
imagem1.buf = buf.split(imagem1, width = 5, i = 1)
imagem2.buf = buf.split(imagem2, width = 5, i = 2)
imagem3.buf = buf.split(imagem3, width = 5, i = 3)

# 0: test, -1: buffer
table(imagem1.buf$fold)

table(imagem2.buf$fold)
```

```{r}
# create the test data
image.buf.test = rbind(imagem1.buf[imagem1.buf$fold==0,],
                       imagem2.buf[imagem2.buf$fold==0,],
                       imagem3.buf[imagem3.buf$fold==0,]) %>%
  dplyr::select(-fold) 

# create training data
image.buf.train = rbind(imagem1.buf[!(imagem1.buf$fold %in% c(0,-1)), ],
                        imagem2.buf[!(imagem2.buf$fold %in% c(0,-1)), ],
                        imagem3.buf[!(imagem3.buf$fold %in% c(0,-1)), ])

table(image.buf.train$fold)
```


```{r}
# plot the split of image1
imagem1.buf %>%
  mutate(fold = recode(as.factor(fold), "1"="training", "2"="training", "3"="training", "4"="training",
                       "0" = "test", "-1"="buffer")) %>%
  ggplot(aes(x = x, y = y, col = factor(fold)))+
  geom_point()+
  labs(x = "x", y = "y", color = "Region")+
  scale_color_brewer(palette = "Blues")+
  theme_bw()
  #scale_color_grey(start = 0.8, end = 0.2)

ggsave("buffer.png")
```

## b 
Baseline
To ensure the ensuing classifier in section 3 is not trivial, we first examine the accuracy of a trivial classifier on the validation set and test set that are previously obtained from the two splitting methods. The trivial classifier assumes all labels to be no cloud. Table 

```{r baseline}
# accuracy on validation set (1st split)
set.seed(123)

idx = sample(unique(image.syst.train$fold), size = 1)
image.syst.val = image.syst.train[image.syst.train$fold==idx,]

acc.val.syst = sum(image.syst.val$label==-1)/sum(image.syst.val$label!=0)

# accuracy on validation set (2nd split)
image.buf.val = image.buf.train[image.buf.train$fold==idx,]

acc.val.buf = sum(image.buf.val$label==-1)/sum(image.buf.val$label!=0)

# accuracy on test set (1st split)
acc.test.syst = sum(image.syst.test$label==-1)/sum(image.syst.test$label!=0)

# accuracy on test set (2nd split)
acc.test.buf = sum(image.buf.test$label==-1)/sum(image.buf.test$label!=0)

# output the table
rbind(
  data.frame(split = 1, set = "validation", accuracy = acc.val.syst),
  data.frame(split = 1, set = "test", accuracy = acc.test.syst),
  data.frame(split = 2, set = "validation", accuracy = acc.val.buf),
  data.frame(split = 2, set = "test", accuracy = acc.test.buf))

```

## c

```{r}
imagebind=rbind(data.frame(imagem1,image=1),
                data.frame(imagem2,image=2),
                data.frame(imagem3,image=3))
## correlation 
cor(imagebind[,4:11],imagebind[,3])
```

```{r}
## remove unlabel
imagebind=rbind(data.frame(imagem1,image=1),
                data.frame(imagem2,image=2),
                data.frame(imagem3,image=3))
imagebind2=imagebind%>%filter(label!=0)
## correlation 
cor(imagebind2[,4:11],imagebind2[,3])
```

# 3

## a

```{r}
# get CVmaster function
source("CVmaster.R")
```

```{r}
# accuracies across folds (systematic assignment)
acc.cv.syst = rbind(
  data.frame(model = "Logistic", 
             accuracy = CVmaster(classifier = "logistic", xtrain = image.syst.train[,4:12], ytrain = image.syst.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "LDA", 
             accuracy = CVmaster(classifier = "LDA", xtrain = image.syst.train[,4:12], ytrain = image.syst.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "QDA", 
             accuracy = CVmaster(classifier = "QDA", xtrain = image.syst.train[,4:12], ytrain = image.syst.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "Naive Bayes", 
             accuracy = CVmaster(classifier = "Naive Bayes", xtrain = image.syst.train[,4:12], ytrain = image.syst.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "KNN", 
             accuracy = CVmaster(classifier = "knn", xtrain = image.syst.train[,4:12], ytrain = image.syst.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "Random Forest", 
             accuracy = CVmaster(classifier = "rf", xtrain = image.syst.train[,4:12], ytrain = image.syst.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "Adaboost", 
             accuracy = CVmaster(classifier = "adaboost", xtrain = image.syst.train[,4:12], ytrain = image.syst.train$label,
                                 K = 10, loss = "accuracy"))
  ) %>%
  pivot_wider(id_cols = model, names_from = accuracy.fold, values_from = accuracy.acc)

acc.cv.syst["average"]=rowMeans(acc.cv.syst[,2:ncol(acc.cv.syst)])
```

```{r}
acc.cv.buf = rbind(
  data.frame(model = "Logistic", 
             accuracy = CVmaster(classifier = "logistic", xtrain = image.buf.train[,4:12], ytrain = image.buf.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "LDA", 
             accuracy = CVmaster(classifier = "LDA", xtrain = image.buf.train[,4:12], ytrain = image.buf.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "QDA", 
             accuracy = CVmaster(classifier = "QDA", xtrain = image.buf.train[,4:12], ytrain = image.buf.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "Naive Bayes", 
             accuracy = CVmaster(classifier = "Naive Bayes", xtrain = image.buf.train[,4:12], ytrain = image.buf.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "KNN", 
             accuracy = CVmaster(classifier = "knn", xtrain = image.buf.train[,4:12], ytrain = image.buf.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "Random Forest", 
             accuracy = CVmaster(classifier = "rf", xtrain = image.buf.train[,4:12], ytrain = image.buf.train$label,
                                 K = 10, loss = "accuracy")),
  data.frame(model = "Adaboost", 
             accuracy = CVmaster(classifier = "adaboost", xtrain = image.buf.train[,4:12], ytrain = image.buf.train$label,
                                 K = 10, loss = "accuracy"))
  ) %>%
  pivot_wider(id_cols = model, names_from = accuracy.fold, values_from = accuracy.acc)

acc.cv.buf["average"]=rowMeans(acc.cv.buf[,2:ncol(acc.cv.buf)])
```

```{r}
## test accuracy
testacc=function(classifier, train, test){
  classifiers=c("logistic","LDA","QDA","Naive Bayes","knn","rf","adaboost")
  if(!(classifier %in% classifiers)){
    print("Please choose classifiers from logistic, LDA, QDA, Naive Bayes, knn, Random Forest, Adaboost.")
    break
  }
  datatrain = train %>% 
    filter(label != 0)
  datatrain$label[datatrain$label == -1] = 0
  datatest = test %>% 
    filter(label != 0)
  datatest$label[datatest$label == -1] = 0
  
  model_formula = as.formula("label~NDAI+SD+CORR+DF+CF+BF+AF+AN")
  
  # logistic regression
  if(classifier == "logistic"){
    glm.fit = glm(model_formula, data = datatrain, family = binomial)
    glm.probs = predict(glm.fit, datatest, type="response")
    glm.pred = rep(0, length(glm.probs))
    glm.pred[glm.probs > 0.5] = 1
    pred = glm.pred
  }
    
  # LDA
  if(classifier == "LDA"){
    lda.fit = lda(model_formula, data = datatrain)
    lda.pred = predict(lda.fit, datatest)
    pred = lda.pred$class
  }
    
  # QDA
  if(classifier == "QDA"){
    qda.fit = qda(model_formula, data = datatrain)
    qda.pred = predict(qda.fit, datatest)
    pred = qda.pred$class
  }
    
  # Naive Bayes
  if(classifier == "Naive Bayes"){
    nb.fit = naiveBayes(model_formula, data = datatrain)
    nb.pred = predict(nb.fit, datatest)
    pred = nb.pred
  }
    
  # KNN
  if(classifier == "knn"){
    train.X = scale(datatrain[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")])
    test.X = scale(datatest[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")])
    knn.pred = knn(train.X, test.X, datatrain$label, k=10)
    pred = knn.pred
  }
  
  # Random forest
  if (classifier == "rf"){
      
    train.X = datatrain[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
    test.X = datatest[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
    rf = randomForest(x = train.X, y = as.factor(datatrain$label), mtry = 3)
    pred = predict(rf, datatest)
      
  }
    
  # Adaboost
  if (classifier == "adaboost"){
      
    boost = gbm(as.character(label) ~ NDAI+SD+CORR+DF+CF+BF+AF+AN, 
                data = datatrain, 
                distribution = "adaboost", 
                n.trees = 3000, 
                interaction.depth = 4)
      
    pred = predict(boost, datatest)
    pred[pred >= 0.5] = 1
    pred[pred < 0.5] = 0
  }  
  
  acc=mean(pred==datatest$label)
  return(acc)
}
```

```{r}
acc.test=matrix(NA,nrow=7,ncol=2)
colnames(acc.test)=c("systematic","buffering")
rownames(acc.test)=c("logistic","LDA","QDA","Naive Bayes","knn","Random Forest","Adaboost")
acc.test[1,1]=testacc("logistic",image.syst.train,image.syst.test)
acc.test[2,1]=testacc("LDA",image.syst.train,image.syst.test)
acc.test[3,1]=testacc("QDA",image.syst.train,image.syst.test)
acc.test[4,1]=testacc("Naive Bayes",image.syst.train,image.syst.test)
acc.test[5,1]=testacc("knn",image.syst.train,image.syst.test)
acc.test[6,1]=testacc("rf",image.syst.train,image.syst.test)
acc.test[7,1]=testacc("adaboost",image.syst.train,image.syst.test)
acc.test[1,2]=testacc("logistic",image.buf.train,image.buf.test)
acc.test[2,2]=testacc("LDA",image.buf.train,image.buf.test)
acc.test[3,2]=testacc("QDA",image.buf.train,image.buf.test)
acc.test[4,2]=testacc("Naive Bayes",image.buf.train,image.buf.test)
acc.test[5,2]=testacc("knn",image.buf.train,image.buf.test)
acc.test[6,2]=testacc("rf",image.buf.train,image.buf.test)
acc.test[7,2]=testacc("adaboost",image.buf.train,image.buf.test)
acc.test
```

## b

```{r}
## systematic
datatrain = image.syst.train %>% 
  filter(label != 0)
datatrain$label[datatrain$label == -1] = 0
datatest = image.syst.test %>% 
  filter(label != 0)
datatest$label[datatest$label == -1] = 0
  
model_formula = as.formula("label~NDAI+SD+CORR+DF+CF+BF+AF+AN")
  
# logistic regression
glm.fit = glm(model_formula, data = datatrain, family = binomial)
glm.probs = predict(glm.fit, datatest, type="response")
glm.pred = rep(0, length(glm.probs))
glm.pred[glm.probs > 0.5] = 1
glm.roc=roc(datatest$label,glm.probs)
    
# LDA
lda.fit = lda(model_formula, data = datatrain)
lda.pred = predict(lda.fit, datatest)
lda.score=lda.pred$posterior[,2]
lda.roc=roc(datatest$label,lda.score)
    
# QDA
qda.fit = qda(model_formula, data = datatrain)
qda.pred = predict(qda.fit, datatest)
qda.score=qda.pred$posterior[,2]
qda.roc=roc(datatest$label,qda.score)

# Naive Bayes
nb.fit = naiveBayes(model_formula, data = datatrain)
nb.pred = predict(nb.fit, datatest)
nb.score=predict(nb.fit,datatest,type="raw")[,2]
nb.roc=roc(datatest$label,nb.score)
  
# KNN
train.X = scale(datatrain[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")])
test.X = scale(datatest[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")])
knn.pred = knn(train.X, test.X, datatrain$label, k=10,prob=TRUE)
knn.score = attr(knn.pred,"prob")
for(i in 1:length(knn.score)){
  if(knn.pred[i]==0){
    knn.score[i]=1-knn.score[i]
  }
}
knn.roc=roc(datatest$label,knn.score)


# Random forest
train.X = datatrain[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
test.X = datatest[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
rf.fit = randomForest(x = train.X, y = as.factor(datatrain$label), mtry = 3)
rf.pred = predict(rf.fit, datatest)
rf.score=predict(rf.fit,datatest,type="prob")[,2]
rf.roc=roc(datatest$label,rf.score)
  
# Adaboost
adaboost.fit = gbm(as.character(label) ~ NDAI+SD+CORR+DF+CF+BF+AF+AN, 
            data = datatrain, 
            distribution = "adaboost", 
            n.trees = 3000, 
            interaction.depth = 4)
adaboost.pred = predict(adaboost.fit, datatest)
adaboost.pred[adaboost.pred >= 0.5] = 1
adaboost.pred[adaboost.pred < 0.5] = 0
adaboost.score=predict(adaboost.fit,datatest)
adaboost.roc=roc(datatest$label,adaboost.score)
```

```{r}
par(mfrow=c(2,4))
plot(glm.roc,print.thres=TRUE,print.auc=TRUE,main="Logistic Regression")
plot(lda.roc,print.thres=TRUE,print.auc=TRUE,main="LDA")
plot(qda.roc,print.thres=TRUE,print.auc=TRUE,main="QDA")
plot(nb.roc,print.thres=TRUE,print.auc=TRUE,main="Naive Bayes")
plot(knn.roc,print.thres=TRUE,print.auc=TRUE,main="knn")
plot(rf.roc,print.thres=TRUE,print.auc=TRUE,main="Random Forest")
plot(adaboost.roc,print.thres=TRUE,print.auc=TRUE,main="Adaboost")
```

```{r}
rocvalue=rbind(
  coords(glm.roc, "best"),
  coords(lda.roc, "best"),
  coords(qda.roc, "best"),
  coords(nb.roc, "best"),
  coords(knn.roc,"best"),
  coords(rf.roc, "best"),
  coords(adaboost.roc, "best")
)
rocvalue
```

ref:
https://stats.stackexchange.com/questions/61521/cut-off-point-in-a-roc-curve-is-there-a-simple-function
https://blog.csdn.net/solo7773/article/details/8699693?spm=1001.2101.3001.6650.11&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-11-8699693-blog-122552363.pc_relevant_aa&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-11-8699693-blog-122552363.pc_relevant_aa&utm_relevant_index=15


## c

```{r}
# logistic
glm.exp = rep(0, length(glm.probs))
glm.exp[glm.probs > rocvalue[1,1]] = 1
glm.cm=confusionMatrix(data=as.factor(glm.exp), reference = as.factor(datatest$label))
glm.cm
```


```{r}
# lda
lda.exp=rep(0,length(lda.score))
lda.exp[lda.score>rocvalue[2,1]]=1
lda.cm=confusionMatrix(data=as.factor(lda.exp), reference = as.factor(datatest$label))
lda.cm
```


```{r}
# qda
qda.exp=rep(0,length(qda.score))
qda.exp[qda.score>rocvalue[3,1]]=1
qda.cm=confusionMatrix(data=as.factor(qda.exp), reference = as.factor(datatest$label))
qda.cm
```


```{r}
# nb
nb.exp=rep(0,length(nb.score))
nb.exp[nb.score>rocvalue[4,1]]=1
nb.cm=confusionMatrix(data=as.factor(nb.exp), reference = as.factor(datatest$label))
nb.cm
```

```{r}
# knn
knn.exp=rep(0,length(knn.score))
knn.exp[knn.score>rocvalue[5,1]]=1
knn.cm=confusionMatrix(data=as.factor(knn.exp), reference = as.factor(datatest$label))
knn.cm
```

```{r}
# rf
rf.exp=rep(0,length(rf.score))
rf.exp[rf.score>rocvalue[6,1]]=1
rf.cm=confusionMatrix(data=as.factor(rf.exp), reference = as.factor(datatest$label))
rf.cm
```


```{r}
# adaboost
adaboost.exp=rep(0,length(adaboost.score))
adaboost.exp[adaboost.score>rocvalue[7,1]]=1
adaboost.cm=confusionMatrix(data=as.factor(adaboost.exp), reference = as.factor(datatest$label))
adaboost.cm
```

```{r}
sum=length(datatest$label)
round(glm.cm$table/sum,3)
round(lda.cm$table/sum,3)
round(qda.cm$table/sum,3)
round(nb.cm$table/sum,3)
round(knn.cm$table/sum,3)
round(rf.cm$table/sum,3)
round(adaboost.cm$table/sum,3)
```

```{r}
glm.cm$table
lda.cm$table
qda.cm$table
nb.cm$table
knn.cm$table
rf.cm$table
adaboost.cm$table
```

# 4

## a

```{r}
# choose random forest
# systematic
```

```{r}
# plot the tree: systematic
datatrain = image.syst.train %>% 
  filter(label != 0)
datatrain$label[datatrain$label == -1] = 0

library(rpart.plot)
rf.fit = rpart(as.factor(label)~NDAI+SD+CORR+DF+CF+BF+AF+AN, data=datatrain)
rpart.plot(rf.fit)
```

```{r}
# ntree, mtry
train.X = datatrain[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
test.X = datatest[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
```


```{r}
mtry=c(2,3,4,8)
ntree=c(1,5,10,20,50,100,200,500,1000,2000,3000)
rffit=function(mtry,ntree){
  rf.fit = randomForest(x = train.X, y = as.factor(datatrain$label), mtry = mtry, ntree=ntree)
  rf.pred = predict(rf.fit, datatest)
  acc=mean(rf.pred==datatest$label)
  return(acc)
}
```

```{r}
N=length(ntree)
M=length(mtry)
rf.acc=matrix(ncol=3,nrow=N*M)
colnames(rf.acc)=c("acc","mtry","ntree")
t=1
for(i in 1:length(mtry)){
  for(j in 1:length(ntree)){
    rf.acc[t,]=c(rffit(mtry[i],ntree[j]),mtry[i],ntree[j])
    t=t+1
  }
}
```

```{r}
write.csv(rf.acc,'rfacc.csv')
```

```{r}
ggplot(data.frame(rf.acc),aes(x=ntree,y=acc,group=as.factor(mtry),color=as.factor(mtry))) +
  geom_line()+
  labs(color="mtry", y="Accuracy", x = "ntree")+
  theme_bw()
```

```{r}
# choose mtry=4, ntree=500
rf.fit = randomForest(x = train.X, y = as.factor(datatrain$label), mtry = 4, ntree=500,importance=TRUE)
rf.fit$importance
varImpPlot(rf.fit)
```

## b

```{r}
# rf model for the whole image
pred1 = predict(rf.fit, imagem1)
pred2 = predict(rf.fit, imagem2)
pred3 = predict(rf.fit, imagem3)
# to be consistent with the label
label1=as.numeric(pred1)*2-3
label2=as.numeric(pred2)*2-3
label3=as.numeric(pred3)*2-3
probs1=predict(rf.fit,imagem1,type="prob")[,2]
probs2=predict(rf.fit,imagem2,type="prob")[,2]
probs3=predict(rf.fit,imagem3,type="prob")[,2]
```

```{r}
# image1
df1=data.frame(imagem1,pred1,label1,probs1,error=label1-imagem1$label)
p11 = df1 %>%
  ggplot(aes(x = x, y = y, col = probs1))+
  geom_point()+
  labs(x = "x", y = "y")+
  theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "black"))+
  tune::coord_obs_pred()
p12 = df1 %>%
  filter(label!=0) %>%
  filter(error!=0) %>%
  ggplot(aes(x=x,y=y,color=as.factor(error))) +
  geom_point() +
  labs(x = "x", y = "y")+
    theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
  tune::coord_obs_pred()

# image2
df2=data.frame(imagem2,pred2,label2,probs2,error=label2-imagem2$label)
p21 = df2 %>%
  ggplot(aes(x = x, y = y, col = probs2))+
  geom_point()+
  labs(x = "x", y = "y")+
  theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "black"))+
  tune::coord_obs_pred()
p22 = df2 %>%
  filter(label!=0) %>%
  filter(error!=0) %>%
  ggplot(aes(x=x,y=y,color=as.factor(error))) +
  geom_point() +
  labs(x = "x", y = "y")+
    theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
  tune::coord_obs_pred()

# image3
df3=data.frame(imagem3,pred3,label3,probs3,error=label3-imagem3$label)
p31 = df3 %>%
  ggplot(aes(x = x, y = y, col = probs3))+
  geom_point()+
  scale_color_continuous(name="probability of being cloudy(1)") +
  labs(x = "x", y = "y")+
  theme(panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "black"))+
  tune::coord_obs_pred()
p32 = df3 %>%
  filter(label!=0) %>%
  filter(error!=0) %>%
  ggplot(aes(x=x,y=y,color=as.factor(error))) +
  geom_point() +
  scale_color_discrete(name="error",labels=c("cloudy predicted as clear","clear predicted as cloudy")) +
  labs(x = "x", y = "y")+
    theme(panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
  tune::coord_obs_pred()

p11+p21+p31+p12+p22+p32+plot_layout(nrow = 2, ncol = 3)
```

## d

```{r}
# plot the tree: buffer
datatrain = image.buf.train %>% 
  filter(label != 0)
datatrain$label[datatrain$label == -1] = 0

library(rpart.plot)
rf.fit = rpart(as.factor(label)~NDAI+SD+CORR+DF+CF+BF+AF+AN, data=datatrain)
rpart.plot(rf.fit)
ggsave("tree_buffer.png")
```

```{r}
## buffering
datatrain = image.buf.train %>% 
  filter(label != 0)
datatrain$label[datatrain$label == -1] = 0
datatest = image.buf.test %>% 
  filter(label != 0)
datatest$label[datatest$label == -1] = 0
  
model_formula = as.formula("label~NDAI+SD+CORR+DF+CF+BF+AF+AN")
  
# logistic regression
glm.fit2 = glm(model_formula, data = datatrain, family = binomial)
glm.probs2 = predict(glm.fit2, datatest, type="response")
glm.pred2 = rep(0, length(glm.probs2))
glm.pred2[glm.probs2 > 0.5] = 1
glm.roc2=roc(datatest$label,glm.probs2)
    
# LDA
lda.fit2 = lda(model_formula, data = datatrain)
lda.pred2 = predict(lda.fit2, datatest)
lda.score2=lda.pred2$posterior[,2]
lda.roc2=roc(datatest$label,lda.score2)
    
# QDA
qda.fit2 = qda(model_formula, data = datatrain)
qda.pred2 = predict(qda.fit2, datatest)
qda.score2=qda.pred2$posterior[,2]
qda.roc2=roc(datatest$label,qda.score2)

# Naive Bayes
nb.fit2 = naiveBayes(model_formula, data = datatrain)
nb.pred2 = predict(nb.fit2, datatest)
nb.score2=predict(nb.fit2,datatest,type="raw")[,2]
nb.roc2=roc(datatest$label,nb.score2)
  
# KNN
train.X = scale(datatrain[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")])
test.X = scale(datatest[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")])
knn.pred2 = knn(train.X, test.X, datatrain$label, k=10,prob=TRUE)
knn.score2 = attr(knn.pred2,"prob")
for(i in 1:length(knn.score2)){
  if(knn.pred2[i]==0){
    knn.score2[i]=1-knn.score2[i]
  }
} 
knn.roc2=roc(datatest$label,knn.score2)


# Random forest
train.X = datatrain[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
test.X = datatest[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
rf.fit2 = randomForest(x = train.X, y = as.factor(datatrain$label), mtry = 3)
rf.pred2 = predict(rf.fit2, datatest)
rf.score2=predict(rf.fit2,datatest,type="prob")[,2]
rf.roc2=roc(datatest$label,rf.score2)
  
# Adaboost
adaboost.fit2 = gbm(as.character(label) ~ NDAI+SD+CORR+DF+CF+BF+AF+AN, 
            data = datatrain, 
            distribution = "adaboost", 
            n.trees = 3000, 
            interaction.depth = 4)
adaboost.pred2 = predict(adaboost.fit2, datatest)
adaboost.pred2[adaboost.pred2 >= 0.5] = 1
adaboost.pred2[adaboost.pred2 < 0.5] = 0
adaboost.score2=predict(adaboost.fit2,datatest)
adaboost.roc2=roc(datatest$label,adaboost.score2)
```

```{r}
par(mfrow=c(2,4))
plot(glm.roc2,print.thres=TRUE,print.auc=TRUE,main="Logistic Regression")
plot(lda.roc2,print.thres=TRUE,print.auc=TRUE,main="LDA")
plot(qda.roc2,print.thres=TRUE,print.auc=TRUE,main="QDA")
plot(nb.roc2,print.thres=TRUE,print.auc=TRUE,main="Naive Bayes")
plot(knn.roc2,print.thres=TRUE,print.auc=TRUE,main="knn")
plot(rf.roc2,print.thres=TRUE,print.auc=TRUE,main="Random Forest")
plot(adaboost.roc2,print.thres=TRUE,print.auc=TRUE,main="Adaboost")
```

```{r}
rocvalue2=rbind(
  coords(glm.roc2, "best"),
  coords(lda.roc2, "best"),
  coords(qda.roc2, "best"),
  coords(nb.roc2, "best"),
  coords(knn.roc2,"best"),
  coords(rf.roc2, "best"),
  coords(adaboost.roc2, "best")
)
rocvalue2
```

```{r}
# logistic
glm.exp2 = rep(0, length(glm.probs2))
glm.exp2[glm.probs2 > rocvalue2[1,1]] = 1
glm.cm2=confusionMatrix(data=as.factor(glm.exp2), reference = as.factor(datatest$label), mode="everything")
glm.cm2
```

```{r}
# lda
lda.exp2=rep(0,length(lda.score2))
lda.exp2[lda.score2>rocvalue2[2,1]]=1
lda.cm2=confusionMatrix(data=as.factor(lda.exp2), reference = as.factor(datatest$label), mode="everything")
lda.cm2
```

```{r}
# qda
qda.exp2=rep(0,length(qda.score2))
qda.exp2[qda.score2>rocvalue2[3,1]]=1
qda.cm2=confusionMatrix(data=as.factor(qda.exp2), reference = as.factor(datatest$label), mode="everything")
qda.cm2
```

```{r}
# nb
nb.exp2=rep(0,length(nb.score2))
nb.exp2[nb.score2>rocvalue2[4,1]]=1
nb.cm2=confusionMatrix(data=as.factor(nb.exp2), reference = as.factor(datatest$label), mode="everything")
nb.cm2
```

```{r}
# knn
knn.exp2=rep(0,length(knn.score2))
knn.exp2[knn.score2>rocvalue2[5,1]]=1
knn.cm2=confusionMatrix(data=as.factor(knn.exp2), reference = as.factor(datatest$label), mode="everything")
knn.cm2
```

```{r}
# rf
rf.exp2=rep(0,length(rf.score2))
rf.exp2[rf.score2>rocvalue2[6,1]]=1
rf.cm2=confusionMatrix(data=as.factor(rf.exp2), reference = as.factor(datatest$label), mode="everything")
rf.cm2
```

```{r}
# adaboost
adaboost.exp2=rep(0,length(adaboost.score2))
adaboost.exp2[adaboost.score2>rocvalue2[7,1]]=1
adaboost.cm2=confusionMatrix(data=as.factor(adaboost.exp2), reference = as.factor(datatest$label), mode="everything")
adaboost.cm2
```

```{r}
sum=length(datatest$label)
round(glm.cm2$table/sum,3)
round(lda.cm2$table/sum,3)
round(qda.cm2$table/sum,3)
round(nb.cm2$table/sum,3)
round(knn.cm2$table/sum,3)
round(rf.cm2$table/sum,3)
round(adaboost.cm2$table/sum,3)
```

```{r}
## buffering
datatrain = image.buf.train %>% 
  filter(label != 0)
datatrain$label[datatrain$label == -1] = 0
datatest = image.buf.test %>% 
  filter(label != 0)
datatest$label[datatest$label == -1] = 0

train.X = datatrain[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
test.X = datatest[, c("NDAI", "SD", "CORR", "DF", "CF", "BF", "AF", "AN")]
```

```{r}
mtry=c(2,3,4,8)
ntree=c(1,5,10,20,50,100,200,500,1000,2000,3000)
rffit=function(mtry,ntree){
  rf.fit = randomForest(x = train.X, y = as.factor(datatrain$label), mtry = mtry, ntree=ntree)
  rf.pred = predict(rf.fit, datatest)
  acc=mean(rf.pred==datatest$label)
  return(acc)
}
```

```{r}
N=length(ntree)
M=length(mtry)
rf.acc2=matrix(ncol=3,nrow=N*M)
colnames(rf.acc2)=c("acc","mtry","ntree")
t=1
for(i in 1:length(mtry)){
  for(j in 1:length(ntree)){
    rf.acc2[t,]=c(rffit(mtry[i],ntree[j]),mtry[i],ntree[j])
    t=t+1
  }
}
```

```{r}
ggplot(data.frame(rf.acc2),aes(x=ntree,y=acc,group=as.factor(mtry),color=as.factor(mtry))) +
  geom_line()+
  labs(color="mtry", y="Accuracy", x = "ntree")+
  theme_bw()
```

```{r}
# choose mtry=3, ntree=500
rf.fit2 = randomForest(x = train.X, y = as.factor(datatrain$label), mtry = 3, ntree=500,importance=TRUE)
rf.fit2$importance
varImpPlot(rf.fit2)
```

```{r}
# rf model for the whole image
pred1 = predict(rf.fit2, imagem1)
pred2 = predict(rf.fit2, imagem2)
pred3 = predict(rf.fit2, imagem3)
# to be consistent with the label
label1=as.numeric(pred1)*2-3
label2=as.numeric(pred2)*2-3
label3=as.numeric(pred3)*2-3
probs1=predict(rf.fit2,imagem1,type="prob")[,2]
probs2=predict(rf.fit2,imagem2,type="prob")[,2]
probs3=predict(rf.fit2,imagem3,type="prob")[,2]
```

```{r}
# image1
df1=data.frame(imagem1,pred1,label1,probs1,error=label1-imagem1$label)
p11 = df1 %>%
  ggplot(aes(x = x, y = y, col = probs1))+
  geom_point()+
  labs(x = "x", y = "y")+
  theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "black"))+
  tune::coord_obs_pred()
p12 = df1 %>%
  filter(label!=0) %>%
  filter(error!=0) %>%
  ggplot(aes(x=x,y=y,color=as.factor(error))) +
  geom_point() +
  labs(x = "x", y = "y")+
    theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
  tune::coord_obs_pred()

# image2
df2=data.frame(imagem2,pred2,label2,probs2,error=label2-imagem2$label)
p21 = df2 %>%
  ggplot(aes(x = x, y = y, col = probs2))+
  geom_point()+
  labs(x = "x", y = "y")+
  theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "black"))+
  tune::coord_obs_pred()
p22 = df2 %>%
  filter(label!=0) %>%
  filter(error!=0) %>%
  ggplot(aes(x=x,y=y,color=as.factor(error))) +
  geom_point() +
  labs(x = "x", y = "y")+
    theme(legend.position = "none",
        panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
  tune::coord_obs_pred()

# image3
df3=data.frame(imagem3,pred3,label3,probs3,error=label3-imagem3$label)
p31 = df3 %>%
  ggplot(aes(x = x, y = y, col = probs3))+
  geom_point()+
  scale_color_continuous(name="probability of being cloudy(1)") +
  labs(x = "x", y = "y")+
  theme(panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "black"))+
  tune::coord_obs_pred()
p32 = df3 %>%
  filter(label!=0) %>%
  filter(error!=0) %>%
  ggplot(aes(x=x,y=y,color=as.factor(error))) +
  geom_point() +
  scale_color_discrete(name="error",labels=c("cloudy predicted as clear","clear predicted as cloudy")) +
  labs(x = "x", y = "y")+
    theme(panel.border = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
  tune::coord_obs_pred()

p11+p21+p31+p12+p22+p32+plot_layout(nrow = 2, ncol = 3)
```
